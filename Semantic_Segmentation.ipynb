{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3850 images belonging to 8 classes.\n",
      "Found 2364 images belonging to 3 classes.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data directory\n",
    "os.chdir(\"C:/Users/Sudhanshu Biyani/Desktop/folder\")\n",
    "\n",
    "image_dimensions = 80\n",
    "\n",
    "# batch size\n",
    "training_batch_size = 64 # larger = better but more computationally costly and memory intensive\n",
    "validate_batch_size = 1 # optimize at runtime for parallel cores, otherwise doesn't matter much\n",
    "\n",
    "# normalization\n",
    "# normalize each chip\n",
    "samplewise_center = True\n",
    "samplewise_std_normalization = True\n",
    "# normalize by larger batches\n",
    "featurewise_center = False\n",
    "featurewise_std_normalization = False\n",
    "\n",
    "# adjacent pixel correllation reduction\n",
    "# never explored\n",
    "zca_whitening = False\n",
    "zca_epsilon = 1e-6\n",
    "\n",
    "# data augmentation \n",
    "# training only\n",
    "transform = 0.1\n",
    "zoom_range = 0.1\n",
    "rotate = 360\n",
    "flip = True\n",
    "\n",
    "datagen_train = ImageDataGenerator(\n",
    "        samplewise_center=samplewise_center,\n",
    "        featurewise_center=featurewise_center,\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=samplewise_std_normalization,\n",
    "        zca_whitening=zca_whitening,\n",
    "        zca_epsilon=zca_epsilon,\n",
    "        rotation_range=rotate,\n",
    "        width_shift_range=transform,\n",
    "        height_shift_range=transform,\n",
    "        shear_range=transform,\n",
    "        zoom_range=zoom_range,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=flip,\n",
    "        vertical_flip=flip,\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=None)\n",
    "\n",
    "# data augmentation \n",
    "# evaluation only\n",
    "transform = 0\n",
    "rotate = 0\n",
    "flip = False\n",
    "\n",
    "datagen_verify = ImageDataGenerator(\n",
    "        samplewise_center=samplewise_center,\n",
    "        featurewise_center=featurewise_center,\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=samplewise_std_normalization,\n",
    "        zca_whitening=zca_whitening,\n",
    "        zca_epsilon=zca_epsilon,\n",
    "        rotation_range=rotate,\n",
    "        width_shift_range=transform,\n",
    "        height_shift_range=transform,\n",
    "        shear_range=transform,\n",
    "        zoom_range=transform,\n",
    "        fill_mode='nearest',\n",
    "        horizontal_flip=flip,\n",
    "        vertical_flip=flip,\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=None)\n",
    "\n",
    "\n",
    "generator_train = datagen_train.flow_from_directory(\n",
    "        'train', \n",
    "        target_size=(image_dimensions,image_dimensions),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=training_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "generator_verify = datagen_verify.flow_from_directory(\n",
    "        'verify', \n",
    "        target_size=(image_dimensions,image_dimensions),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=validate_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# define MobileNet architecture\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "model = MobileNet(\n",
    "                  input_shape=(image_dimensions, image_dimensions,3),     \n",
    "                  alpha=0.25,\n",
    "                  depth_multiplier=1,\n",
    "                  dropout=0.5,\n",
    "                  include_top=True, \n",
    "                  weights=None,\n",
    "                  input_tensor=None,\n",
    "                  pooling=None,\n",
    "                  classes=8\n",
    "                  )\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected reshape_2 to have shape (8,) but got array with shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-aaeafe33fdb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnValbatches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         callbacks=[checkpointer])\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2242\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2243\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2244\u001b[1;33m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[0;32m   2245\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2246\u001b[0m                             \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2376\u001b[0m                                      \u001b[1;34m'or (x, y). Found: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m                                      str(generator_output))\n\u001b[1;32m-> 2378\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2380\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         x, y, sample_weights = self._standardize_user_data(\n\u001b[0;32m   1917\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1919\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected reshape_2 to have shape (8,) but got array with shape (3,)"
     ]
    }
   ],
   "source": [
    "# Train CNN\n",
    "\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "nEpochs = 500\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "        filepath='sat_mobilenet_v0.h5', \n",
    "        monitor='val_loss', \n",
    "        verbose=1, \n",
    "        save_best_only=True,\n",
    "        mode='auto',\n",
    "        save_weights_only=False)\n",
    "\n",
    "nFiles = sum([len(files) for r, d, files in os.walk(\"C:/Users/Sudhanshu Biyani/Desktop/folder/train\")])\n",
    "nBatches = nFiles//training_batch_size\n",
    "\n",
    "nValFiles = sum([len(files) for r, d, files in os.walk(\"C:/Users/Sudhanshu Biyani/Desktop/folder/verify\")])\n",
    "nValbatches = nValFiles//validate_batch_size\n",
    "\n",
    "hist = model.fit_generator(\n",
    "        generator_train,\n",
    "        steps_per_epoch=nBatches,\n",
    "        epochs=nEpochs,\n",
    "        verbose=2,\n",
    "        validation_data=generator_verify,\n",
    "        validation_steps=nValbatches,\n",
    "        max_queue_size=10,\n",
    "        callbacks=[checkpointer])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER EVAL TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# LOAD Pretrained MOBILENET MODEL\n",
    "\n",
    "from keras.applications import mobilenet\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('sat_mobilenet_v0.h5', custom_objects={\n",
    "                   'relu6': mobilenet.relu6,\n",
    "                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss']\n",
      "1.1489999845828474\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE\n",
    "\n",
    "nValFiles = sum([len(files) for r, d, files in os.walk(\"C:/Users/Sudhanshu Biyani/Desktop/folder/verify\")])\n",
    "nValbatches = nValFiles//validate_batch_size\n",
    "\n",
    "evaluation = model.evaluate_generator(\n",
    "        generator_verify, \n",
    "        steps=nValbatches, \n",
    "        max_queue_size=10)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1176 images belonging to 8 classes.\n",
      "1176/1176 [==============================] - 14s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "# PREDICT\n",
    "\n",
    "generator_predict = datagen_verify.flow_from_directory(\n",
    "        'verify', \n",
    "        target_size=(image_dimensions,image_dimensions),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=validate_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "nValFiles = sum([len(files) for r, d, files in os.walk(\"C:/Users/Sudhanshu Biyani/Desktop/folder/verify\")])\n",
    "nValbatches = nValFiles//validate_batch_size\n",
    "\n",
    "predictions = model.predict_generator(\n",
    "        generator_predict, \n",
    "        steps=nValbatches, \n",
    "        max_queue_size=10,\n",
    "        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello)\n"
     ]
    }
   ],
   "source": [
    "#RUN ON IMAGE FROM DRONE\n",
    "import imageio\n",
    "print (\"hello)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'ntpath' from 'C:\\\\Anaconda3\\\\lib\\\\ntpath.py'>\n"
     ]
    }
   ],
   "source": [
    "print (os.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-5-2f46fd82dfa9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-2f46fd82dfa9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    temp = imageio.imread('C:\\Users\\Sudhanshu Biyani\\OneDrive - Arizona State University\\Semester 2\\CSE 591 - Perception in Robotics\\Project\\100x100 Slices\\Camelback\\x0y0.png')\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "temp = imageio.imread('C:\\Users\\Sudhanshu Biyani\\OneDrive - Arizona State University\\Semester 2\\CSE 591 - Perception in Robotics\\Project\\100x100 Slices\\Camelback\\x0y0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file: 'C:\\Users\\Sudhanshu Biyani\\Desktop\\x0y0.pmg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cf3190bea116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Sudhanshu Biyani/Desktop/x0y0.pmg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    250\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No such file: 'C:\\Users\\Sudhanshu Biyani\\Desktop\\x0y0.pmg'"
     ]
    }
   ],
   "source": [
    "temp = imageio.imread('C:/Users/Sudhanshu Biyani/Desktop/x0y0.pmg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = imageio.imread('C:/Users/Sudhanshu Biyani/Desktop/x0y0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[199 195 163]\n",
      "  [196 190 163]\n",
      "  [220 229 229]\n",
      "  ...\n",
      "  [175 160 146]\n",
      "  [172 158 143]\n",
      "  [180 168 151]]\n",
      "\n",
      " [[199 192 165]\n",
      "  [192 192 162]\n",
      "  [219 227 228]\n",
      "  ...\n",
      "  [172 167 144]\n",
      "  [172 158 138]\n",
      "  [175 156 142]]\n",
      "\n",
      " [[199 195 165]\n",
      "  [191 182 155]\n",
      "  [220 226 228]\n",
      "  ...\n",
      "  [174 166 147]\n",
      "  [166 158 139]\n",
      "  [173 169 145]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[158 159 147]\n",
      "  [131 138 138]\n",
      "  [131 142 135]\n",
      "  ...\n",
      "  [156 158 151]\n",
      "  [151 150 148]\n",
      "  [152 159 152]]\n",
      "\n",
      " [[153 154 153]\n",
      "  [110 110  93]\n",
      "  [152 154 146]\n",
      "  ...\n",
      "  [157 158 153]\n",
      "  [162 164 155]\n",
      "  [153 162 155]]\n",
      "\n",
      " [[109 119 108]\n",
      "  [120 126 116]\n",
      "  [139 145 135]\n",
      "  ...\n",
      "  [132 139 129]\n",
      "  [113 115 107]\n",
      "  [107 108 106]]]\n"
     ]
    }
   ],
   "source": [
    "print (temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "scipy.misc.imsave('outfile.jpg', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
