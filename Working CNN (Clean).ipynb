{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from os.path import isfile, join\n",
    "from keras.applications import mobilenet\n",
    "from keras.models import load_model\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from matplotlib import colors\n",
    "import skimage\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'alt.csv', 'Bebop', 'Bebop2_20180414154341-0700.mp4', 'Bebop2_20180414163256-0700.mp4', 'bebop_mobilenet_v0.h5', 'Frames', 'Frames_New', 'out.mp4', 'out1.mp4', 'Semantic_Segmentation.ipynb', 'Video Frame Extraction.ipynb', 'Working CNN Boi.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# normalize each chip\n",
    "samplewise_center = True\n",
    "samplewise_std_normalization = True\n",
    "# normalize by larger batches\n",
    "featurewise_center = False\n",
    "featurewise_std_normalization = False\n",
    "\n",
    "# adjacent pixel correllation reduction\n",
    "# never explored\n",
    "zca_whitening = False\n",
    "zca_epsilon = 1e-6\n",
    "\n",
    "# data augmentation \n",
    "# training only\n",
    "transform = 0\n",
    "zoom_range = 0\n",
    "color_shift = 0\n",
    "rotate = 0\n",
    "flip = False\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "        samplewise_center=samplewise_center,\n",
    "        featurewise_center=featurewise_center,\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=samplewise_std_normalization,\n",
    "        zca_whitening=zca_whitening,\n",
    "        zca_epsilon=zca_epsilon,\n",
    "        rotation_range=rotate,\n",
    "        width_shift_range=transform,\n",
    "        height_shift_range=transform,\n",
    "        shear_range=transform,\n",
    "        zoom_range=zoom_range,\n",
    "        channel_shift_range=color_shift, \n",
    "        fill_mode='constant',\n",
    "        cval=0,\n",
    "        horizontal_flip=flip,\n",
    "        vertical_flip=flip,\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=None)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "generator_test = datagen_test.flow(\n",
    "        'Training_Data', \n",
    "        target_size=(image_dimensions,image_dimensions),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=training_batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module to operate on each individual frame of the video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights\n",
    "model = load_model('bebop_mobilenet_v0.h5', custom_objects={\n",
    "                   'relu6': mobilenet.relu6,\n",
    "                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessChip (frame):\n",
    "    #result_feature_map = np.zeros((9,16,7))  #CNN feature map to be returned\n",
    "    values = np.zeros((9,16,3))\n",
    "    chips = np.zeros((144,120,120,3))\n",
    "    \n",
    "    for i in range(0,9):\n",
    "        for j in range(0,16):\n",
    "            chips[16*i+j] = frame[120*i:120*(i+1), 120*j:120*(j+1), :]\n",
    "            \n",
    "    generator_test = datagen_test.flow(\n",
    "        chips, \n",
    "        batch_size=144,\n",
    "        shuffle=False)\n",
    "    \n",
    "    #return values\n",
    "    return model.predict_generator(generator_test,\n",
    "                                  steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Decision Algo Definition\n",
    "\n",
    "#Function to find the closest roof/driveway\n",
    "def closest(list,img_center):\n",
    "    closest=list[0]\n",
    "    for c in list:\n",
    "        if np.linalg.norm(c-img_center) < np.linalg.norm(closest-img_center):\n",
    "            closest = c\n",
    "    return closest\n",
    "\n",
    "#Sliding window function\n",
    "def sliding_window_view(arr, shape):\n",
    "    n = np.array(arr.shape) \n",
    "    o = n - shape + 1 # output shape\n",
    "    strides = arr.strides\n",
    "    \n",
    "    new_shape = np.concatenate((o, shape), axis=0)\n",
    "    new_strides = np.concatenate((strides, strides), axis=0)\n",
    "    return np.lib.stride_tricks.as_strided(arr ,new_shape, new_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Decision algo with input of 9x16 array at which image was taken.\n",
    "def decision_algo(image_frame):\n",
    "    image_frame[image_frame==0]=3\n",
    "    \n",
    "    ### READ THE ALTITUDE FROM CSV FILE ###\n",
    "    #Read alt.csv\n",
    "    with open('alt.csv', 'r') as csvfile:\n",
    "        alt_list = [line.rstrip('\\n') for line in csvfile]\n",
    "\n",
    "    #Choose last value in alt_list        \n",
    "    altitude=int(alt_list[-1]) #in meters\n",
    "\n",
    "    \n",
    "    ### ALGORITHM TO FIND CLOSEST DRIVEWAY ###\n",
    "    #Center of the 9x16 array\n",
    "    img_center=np.array([4,7.5])\n",
    "\n",
    "    #Label all the driveways and roofs\n",
    "    driveway, num_driveway = label(image_frame==1)\n",
    "    roof, num_roof = label(image_frame==2)\n",
    "\n",
    "    #Save number of driveways and roofs into array\n",
    "    d=np.arange(1,num_driveway+1)\n",
    "    r=np.arange(1,num_roof+1)\n",
    "    \n",
    "    if(len(d)<1):\n",
    "        print(\"No driveway found, return to base\")\n",
    "    else:\n",
    "        #Find the center of the all the driveways\n",
    "        driveway_center=center_of_mass(image_frame,driveway,d)\n",
    "        roof_center=center_of_mass(image_frame,roof,r)\n",
    "\n",
    "        #Find the closest roof to the center of the image\n",
    "        if(len(roof_center)>0):\n",
    "            closest_roof=closest(roof_center,img_center)\n",
    "        else:\n",
    "            #if no roof is found, set closest_roof as center of image\n",
    "            closest_roof=img_center\n",
    "            print(\"Roof center list empty\")\n",
    "\n",
    "        #Find the closest driveway to the closest roof\n",
    "        closest_driveway=closest(driveway_center,np.asarray(closest_roof))\n",
    "\n",
    "        ### ALGORITHM TO FIND 3x3 DRIVEWAY TO LAND ###\n",
    "        #If altitude is 5m or less, look for a 3x3 sliding window of 1's, if found, Land.\n",
    "        #At 5m, a 3x3 will be equivalent to 1.5m x 1.5m.\n",
    "        if(altitude<=5.0):\n",
    "            #Creates a 7x10 ndarray with all the 3x3 submatrices\n",
    "            sub_image=sliding_window_view(image_frame,(3,3))\n",
    "\n",
    "            #Empty list\n",
    "            driveway_list=[]\n",
    "\n",
    "            #Loop through the 7x14 ndarray\n",
    "            for i in range(0,7):\n",
    "                for j in range(i,14):\n",
    "                    #Calculate the total of the  submatrices\n",
    "                    output=sum(sum(sub_image[i,j]))\n",
    "                    #if the output is 9, that means we have a 3x3 that is all driveway\n",
    "                    if output==9:\n",
    "                        #append the i(row) and j(column) to a list declared previously\n",
    "                        #we add 1 to the i and j to find the center of the 3x3\n",
    "                        driveway_list.append((i+1,j+1))\n",
    "\n",
    "            if(len(driveway_list)>0):\n",
    "                #Call closest function to find driveway closest to house.             \n",
    "                closest_driveway=closest(driveway_list,np.asarray(closest_roof))\n",
    "                print(closest_driveway)\n",
    "                print(\"Safe to land\")\n",
    "            else:\n",
    "                print(\"Need to fly lower\")\n",
    "        \n",
    "\n",
    "\n",
    "        ### SCALE CLOSEST DRIVEWAY CENTER TO REAL WORLD COORDINATES AND SAVE TO CSV ###\n",
    "        scaler=0.205/(216.26*altitude**-0.953) #m/pixel\n",
    "        if(len(driveway_center)>0):\n",
    "            print (closest_driveway)\n",
    "            move_coordinates=([4,7.5]-np.asarray(closest_driveway)) #Find coordinates relative to center of image\n",
    "            move_coordinates=np.asarray(move_coordinates)*np.asarray(scaler)*120 #60 is the center of the 120x120 superpixel\n",
    "            move_coordinates=np.append(move_coordinates,(altitude-2)) #Add altitude to array\n",
    "            print (move_coordinates)\n",
    "            with open('coords.csv', 'w') as csvfile:\n",
    "                filewriter = csv.writer(csvfile, delimiter=',')\n",
    "                filewriter.writerow(move_coordinates)\n",
    "            with open('coordinates_history.csv', 'a', newline='') as csvfile:\n",
    "                filewriter = csv.writer(csvfile, delimiter=',')\n",
    "                filewriter.writerow(move_coordinates)      \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap (feature_map, frame):\n",
    "    color_mask = np.zeros((1080,1920,3))\n",
    "    temp_frame = skimage.img_as_float(frame)\n",
    "    alpha = 0.6\n",
    "    for i in range (0,9):\n",
    "        for j in range (0,16):\n",
    "            if feature_map[i][j] == 2:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [0, 0, 1] #Blue, House\n",
    "            elif feature_map[i][j] == 1:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [0, 1, 0] #Green, Concrete\n",
    "            else:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [1, 0, 0] #Red, Don't Care\n",
    "    color_mask_hsv = colors.rgb_to_hsv(color_mask)\n",
    "    frame_hsv = colors.rgb_to_hsv(temp_frame)\n",
    "    frame_hsv[..., 0] = color_mask_hsv[..., 0]\n",
    "    frame_hsv[..., 1] = color_mask_hsv[..., 1] * alpha\n",
    "    frame_masked = colors.hsv_to_rgb(frame_hsv)\n",
    "    return frame_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_arr (arr) :\n",
    "    arr = arr + 1\n",
    "    arr[arr>2] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Module to iterate through each frame in video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VideoToFrames (vid):\n",
    "    \n",
    "    count = 0 # Can be removed. Just to verify number of frames\n",
    "    #count_pavement = []\n",
    "    t = time.time()\n",
    "    for image in vid.iter_data(): #Iterate through every frame in Video\n",
    "        #image: numpy array containing image information\n",
    "        \n",
    "        if count % 100 == 0:\n",
    "            feature_map = ProcessChip(image)\n",
    "            arr = heatmap(np.reshape(correct_arr(np.argmax(ProcessChip(image), axis=1)), (9,16)), image)\n",
    "            cv2.imwrite('./Frames_New//frame%d.jpg'%count, arr*255)\n",
    "        count += 1\n",
    "    elapsed = time.time() - t \n",
    "    return elapsed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if count % 600 == 0:\n",
    "            print (count)\n",
    "            feature_map = ProcessChip(image)\n",
    "            arr = correct_arr(np.argmax(ProcessChip(image), axis=1))\n",
    "            arr = np.reshape(arr,(9,16))\n",
    "            plt.imshow(heatmap(arr, image), interpolation='nearest')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_frames_to_video(pathIn,pathOut,fps):\n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    " \n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: int(x[5:-4]))\n",
    " \n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each file\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        print(filename)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    " \n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    " \n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Bebop/Bebop2_20180422173922-0700.mp4' #Add path to video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: the frame size for reading (1920, 1080) is different from the source frame size (800, 450).\n"
     ]
    }
   ],
   "source": [
    "vid = imageio.get_reader(filename, 'ffmpeg') #You can use any reader of your choice\n",
    "#print (vid.iter_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken = VideoToFrames(vid) #Passing the video to be analyzed frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken 270.3919630050659\n"
     ]
    }
   ],
   "source": [
    "print ('Total time taken %s'%time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Frames_New/frame0.jpg\n",
      "./Frames_New/frame1.jpg\n",
      "./Frames_New/frame100.jpg\n",
      "./Frames_New/frame200.jpg\n",
      "./Frames_New/frame300.jpg\n",
      "./Frames_New/frame400.jpg\n",
      "./Frames_New/frame500.jpg\n",
      "./Frames_New/frame600.jpg\n",
      "./Frames_New/frame700.jpg\n",
      "./Frames_New/frame800.jpg\n",
      "./Frames_New/frame900.jpg\n",
      "./Frames_New/frame1000.jpg\n",
      "./Frames_New/frame1100.jpg\n",
      "./Frames_New/frame1200.jpg\n",
      "./Frames_New/frame1300.jpg\n",
      "./Frames_New/frame1400.jpg\n",
      "./Frames_New/frame1500.jpg\n",
      "./Frames_New/frame1600.jpg\n",
      "./Frames_New/frame1700.jpg\n",
      "./Frames_New/frame1800.jpg\n",
      "./Frames_New/frame1900.jpg\n",
      "./Frames_New/frame2000.jpg\n",
      "./Frames_New/frame2100.jpg\n",
      "./Frames_New/frame2200.jpg\n",
      "./Frames_New/frame2300.jpg\n",
      "./Frames_New/frame2400.jpg\n",
      "./Frames_New/frame2500.jpg\n",
      "./Frames_New/frame2600.jpg\n",
      "./Frames_New/frame2700.jpg\n",
      "./Frames_New/frame2800.jpg\n",
      "./Frames_New/frame2900.jpg\n",
      "./Frames_New/frame3000.jpg\n",
      "./Frames_New/frame3100.jpg\n",
      "./Frames_New/frame3200.jpg\n",
      "./Frames_New/frame3300.jpg\n",
      "./Frames_New/frame3400.jpg\n",
      "./Frames_New/frame3500.jpg\n",
      "./Frames_New/frame3600.jpg\n",
      "./Frames_New/frame3700.jpg\n",
      "./Frames_New/frame3800.jpg\n",
      "./Frames_New/frame3900.jpg\n",
      "./Frames_New/frame4000.jpg\n",
      "./Frames_New/frame4100.jpg\n",
      "./Frames_New/frame4200.jpg\n",
      "./Frames_New/frame4300.jpg\n",
      "./Frames_New/frame4400.jpg\n",
      "./Frames_New/frame4500.jpg\n",
      "./Frames_New/frame4600.jpg\n",
      "./Frames_New/frame4700.jpg\n",
      "./Frames_New/frame4800.jpg\n",
      "./Frames_New/frame4900.jpg\n"
     ]
    }
   ],
   "source": [
    "convert_frames_to_video('./Frames_New/', 'out1.mp4', 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
