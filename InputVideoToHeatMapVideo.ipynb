{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INSTRUCTIONS**\n",
    "\n",
    "`1st Video`: run notebook AS-IS.\n",
    "\n",
    "**After running the notebook for `1st Video` and getting the output video:**\n",
    "\n",
    "`2nd Video`: comment lines having the comment `1st Video` and uncomment lines having the comment `2nd Video`, rerun the cells and run notebook AS-IS.\n",
    "\n",
    "**ALL CELLS WHERE CHANGES ARE REQUIRED HAVE A CELL ABOVE IT TO NOTIFY YOU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab\n",
    "import imageio\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "from os.path import isfile, join\n",
    "from keras.applications import mobilenet\n",
    "from keras.models import load_model\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from matplotlib import colors\n",
    "import skimage\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Bebop', 'Bebop2_20180414154341-0700.mp4', 'Bebop2_20180414163256-0700.mp4', 'bebop_mobilenet_overfit_v1.h5', 'bebop_mobilenet_v0.h5', 'Frames', 'Frames_1', 'Frames_2', 'Frames_New', 'InputVideoToHeatMapVideo.ipynb', 'out.mp4', 'out1.mp4', 'Semantic_Segmentation.ipynb', 'Video Frame Extraction.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "# normalize each chip\n",
    "samplewise_center = True\n",
    "samplewise_std_normalization = True\n",
    "# normalize by larger batches\n",
    "featurewise_center = False\n",
    "featurewise_std_normalization = False\n",
    "\n",
    "# adjacent pixel correllation reduction\n",
    "# never explored\n",
    "zca_whitening = False\n",
    "zca_epsilon = 1e-6\n",
    "\n",
    "# data augmentation \n",
    "# training only\n",
    "transform = 0\n",
    "zoom_range = 0\n",
    "color_shift = 0\n",
    "rotate = 0\n",
    "flip = False\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "        samplewise_center=samplewise_center,\n",
    "        featurewise_center=featurewise_center,\n",
    "        featurewise_std_normalization=featurewise_std_normalization,\n",
    "        samplewise_std_normalization=samplewise_std_normalization,\n",
    "        zca_whitening=zca_whitening,\n",
    "        zca_epsilon=zca_epsilon,\n",
    "        rotation_range=rotate,\n",
    "        width_shift_range=transform,\n",
    "        height_shift_range=transform,\n",
    "        shear_range=transform,\n",
    "        zoom_range=zoom_range,\n",
    "        channel_shift_range=color_shift, \n",
    "        fill_mode='constant',\n",
    "        cval=0,\n",
    "        horizontal_flip=flip,\n",
    "        vertical_flip=flip,\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights\n",
    "model = load_model('bebop_mobilenet_overfit_v1.h5', custom_objects={\n",
    "                   'relu6': mobilenet.relu6,\n",
    "                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessChip (frame):\n",
    "\n",
    "    values = np.zeros((9,16,3))\n",
    "    chips = np.zeros((144,128,128,3))\n",
    "    \n",
    "    for i in range(0,9):\n",
    "        for j in range(0,16):\n",
    "            chips[16*i+j] = resize(frame[120*i:120*(i+1), 120*j:120*(j+1), :], (128,128,3))\n",
    "            \n",
    "    generator_test = datagen_test.flow(\n",
    "        chips, \n",
    "        batch_size=144,\n",
    "        shuffle=False)\n",
    "    \n",
    "    return model.predict_generator(generator_test,\n",
    "                                  steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap (feature_map, frame):\n",
    "    \n",
    "    color_mask = np.zeros((1080,1920,3))\n",
    "    temp_frame = skimage.img_as_float(frame)\n",
    "    alpha = 0.6\n",
    "    for i in range (0,9):\n",
    "        for j in range (0,16):\n",
    "            if feature_map[i][j] == 2:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [0, 0, 1] #Blue, House\n",
    "            elif feature_map[i][j] == 1:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [0, 1, 0] #Green, Concrete\n",
    "            else:\n",
    "                color_mask[120*i:120*(i+1), 120*j:120*(j+1), :] = [1, 0, 0] #Red, Don't Care\n",
    "    color_mask_hsv = colors.rgb_to_hsv(color_mask)\n",
    "    frame_hsv = colors.rgb_to_hsv(temp_frame)\n",
    "    frame_hsv[..., 0] = color_mask_hsv[..., 0]\n",
    "    frame_hsv[..., 1] = color_mask_hsv[..., 1] * alpha\n",
    "    frame_masked = colors.hsv_to_rgb(frame_hsv)\n",
    "    \n",
    "    return frame_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_arr (arr) :\n",
    "    \n",
    "    arr = arr + 1\n",
    "    arr[arr>2] = 0\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make changes to next cell while running `2nd Video`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VideoToFrames (vid):\n",
    "    \n",
    "    count = 0\n",
    "    for image in vid.iter_data(): \n",
    "        #image: numpy array containing image information\n",
    "        feature_map = ProcessChip(image)\n",
    "        arr = heatmap(np.reshape(correct_arr(np.argmax(ProcessChip(image), axis=1)), (9,16)), image)\n",
    "        cv2.imwrite('./Frames_1/frame%d.jpg'%count, arr*255) #1st Video\n",
    "        #cv2.imwrite('./Frames_2/frame%d.jpg'%count, arr*255)  #2nd Video\n",
    "        count += 1\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_frames_to_video(pathIn,pathOut,fps):\n",
    "    \n",
    "    frame_array = []\n",
    "    files = [f for f in os.listdir(pathIn) if isfile(join(pathIn, f))]\n",
    " \n",
    "    #for sorting the file names properly\n",
    "    files.sort(key = lambda x: int(x[5:-4]))\n",
    " \n",
    "    for i in range(len(files)):\n",
    "        filename=pathIn + files[i]\n",
    "        #reading each file\n",
    "        img = cv2.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        print(filename)\n",
    "        #inserting the frames into an image array\n",
    "        frame_array.append(img)\n",
    " \n",
    "    out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    " \n",
    "    for i in range(len(frame_array)):\n",
    "        # writing to a image array\n",
    "        out.write(frame_array[i])\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make changes to next cell while running `2nd Video`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Bebop/Bebop2_20180422171942-0700.mp4' #1st Video\n",
    "#filename = './Bebop/Bebop2_20180422171508-0700.mp4'  #2nd Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: the frame size for reading (1920, 1080) is different from the source frame size (800, 450).\n"
     ]
    }
   ],
   "source": [
    "vid = imageio.get_reader(filename, 'ffmpeg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anshu\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "VideoToFrames(vid) #Passing the video to be analyzed frame by frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make changes to next cell while running `2nd Video`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Frames_1/frame0.jpg\n",
      "./Frames_1/frame1.jpg\n",
      "./Frames_1/frame2.jpg\n",
      "./Frames_1/frame3.jpg\n",
      "./Frames_1/frame4.jpg\n",
      "./Frames_1/frame5.jpg\n",
      "./Frames_1/frame6.jpg\n",
      "./Frames_1/frame7.jpg\n",
      "./Frames_1/frame8.jpg\n",
      "./Frames_1/frame9.jpg\n",
      "./Frames_1/frame10.jpg\n"
     ]
    }
   ],
   "source": [
    "convert_frames_to_video('./Frames_1/', 'out_942.mp4', 23.82) #1st Video\n",
    "#convert_frames_to_video('./Frames_2/', 'out_508.mp4', 23.41) #2nd Video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
